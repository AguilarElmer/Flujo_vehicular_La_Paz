# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jjmgpxIng8rrVrjC6Dvb3utCGlLGNBJz
"""

# Importa las bibliotecas necesarias
import os
import numpy as np
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input
from sklearn.cluster import KMeans
from google.colab import drive

# Montar Google Drive
drive.mount('/content/drive')

# Especifica la ruta a tus datos
img_folder = '/content/drive/MyDrive/sistemas inteligentes/dataset entrada/autos'

# Carga el modelo preentrenado VGG16
model = VGG16(weights='imagenet', include_top=False)

# Función para cargar y preprocesar la imagen
def load_image(img_path):
    img = image.load_img(img_path, target_size=(224, 224))
    img_data = image.img_to_array(img)
    img_data = np.expand_dims(img_data, axis=0)
    img_data = preprocess_input(img_data)
    return img_data

# Recorre el directorio de imágenes y extrae características
features = []
file_list = []
for img_path in os.listdir(img_folder):
    img_path_full = os.path.join(img_folder, img_path)
    if os.path.isfile(img_path_full):
        img_data = load_image(img_path_full)
        feature = model.predict(img_data)
        features.append(feature.flatten())
        file_list.append(img_path)

# Aplica K-means clustering
kmeans = KMeans(n_clusters=5, random_state=0)  # Aquí 5 es un número hipotético de clases de coches, tendrás que ajustar esto a tu caso
kmeans.fit(features)

# Imprime las etiquetas de las imágenes
for i, label in enumerate(kmeans.labels_):
    print(file_list[i], label)

from sklearn.metrics import silhouette_samples

# Calcula los coeficientes de silueta de cada punto
silhouette_vals = silhouette_samples(features, kmeans.labels_)

# Obtiene el promedio de coeficiente de silueta para cada cluster
for i in range(5):  # Aquí 5 es el número hipotético de clusters, ajusta esto a tu caso
    cluster_silhouette_vals = silhouette_vals[kmeans.labels_ == i]
    print("Coeficiente de Silueta para el cluster", i, ":", np.mean(cluster_silhouette_vals))

import shutil

# Crea un directorio para cada cluster
output_dir = '/content/drive/MyDrive/sistemas inteligentes/dataset salida'
for i in range(5):  # Aquí 5 es el número hipotético de clusters, ajusta esto a tu caso
    os.makedirs(os.path.join(output_dir, 'cluster' + str(i)), exist_ok=True)

# Mueve las imágenes a los directorios correspondientes
for i, label in enumerate(kmeans.labels_):
    img_path_full = os.path.join(img_folder, file_list[i])
    shutil.copy(img_path_full, os.path.join(output_dir, 'cluster' + str(label)))

"""El Coeficiente de Silueta mide cuán cerca están los puntos en el mismo cluster y cuán lejos están los puntos en diferentes clusters. Los valores van de -1 a 1, y un valor más alto indica que los clusters están bien separados y que los puntos están cerca unos de otros dentro del mismo cluster.

"""

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Convertir la lista de características a un array NumPy
features_np = np.array(features)

# Reducción de la dimensionalidad con t-SNE
tsne = TSNE(n_components=2, random_state=0)
reduced_features = tsne.fit_transform(features_np)

# Crear un scatter plot
plt.figure(figsize=(6, 5))
colors = ['r', 'g', 'b', 'c', 'm']  # Ajusta esto a tu número de clusters
for i, color in enumerate(colors):
    plt.scatter(reduced_features[kmeans.labels_ == i, 0], reduced_features[kmeans.labels_ == i, 1], c=color)
plt.show()